task: train
save_log: True
wandb: False
streaming: True   #SoundSpring-S

lite_model: False
lite_model_config:
  "num_blocks": 6
  "dim": 256

model_path: "ckpt/SoundSpring-S_libri16k/base_d512_b12.ckpt" #12 layers, 512 dim # random bandwidth streaming 1.5, 3, 6, 12kbps
lite_model_path: #indexed by 'num_blocks' 'dim'
  3:
      512: "ckpt/SoundSpring-S_libri16k/lite_d512_b3.ckpt"
  6:
      256: "ckpt/SoundSpring-S_libri16k/lite_d256_b6.ckpt"
      512: "ckpt/SoundSpring-S_libri16k/lite_d256_b6.ckpt"
  12:
      256: "ckpt/SoundSpring-S_libri16k/lite_d256_b12.ckpt"

target_bandwidths: [1.5, 3., 6, 12., 18]
test_bandwidth: [1.5, 3., 6, 12., 18]

train_cfg:
  resume_training: False  # resume training LM
  train_mode: 'lm_only'  # 'lm_only', 'ft_decoder', 'full'
  weighted_loss: False

  device: 'cuda'

  N_EPOCHS: 1000
  TEST_NUMBER: 100
  epoch_begin: 1
  freeze_discriminator: False
  freeze_discriminator_warmupG_epoch: 2

  ckpt_save_every: 10
  print_every: 200

  # not used in lm_only mode
  lr_enc: 3e-4
  lr_dis: 1e-4
  lr_config:
    warmup_steps: 5
    hold_steps: 20  # steps after warmup (not include the warmup steps)
    max_steps: 1000
    decay_rate: 0.5  # set 1.0 to decay faster
    min_lr: 1e-6


wandb_cfg:
  project_name: 'AudioMLM' # Set the project where this run will be logged
  run_name: "[SoundSpring]"
  note: ""

BATCH_SIZE: 32
dataset: LibriSpeech # LibriSpeech, aishe113
dataset_cfg:
  LibriSpeech:
    datasetClass: AudioDataset4
    max_duration_sec: None
  aishe113:
    datasetClass: AudioDataset4
    max_duration_sec: None


SAMPLE_RATE: 16000
Resample_rate: 16000
input_duration: 1000  # ms
overlap_ratio: 0.1
EXTRACT_MODE: 1


eval_cfg:
  "bandwidth": 6
  "packet_loss": 0.6
  "sim_mode": 'ratio'
  "slices": 10
  "num_stages_to_pred": 4
  "context_mode": 'temporal_stride'
  "fec": False
  "fec_mode": '01'
  "save": True
  "compress": False
  "vqlayer_bins": [1, 1, 2, 4, 8] #[base * lm_config["base_layer_n_q"] for base in [1 1 2 4 8]]

stream_cfg:
  "lookahead_frames": 2
  "interval": 5
  "max_context_frames": 15  # 50

# used in mfcc loss
WINDOW_SIZE: 512

model_config:
  load: False  # [automatically set] load from pretrained audio codec
  Encodec_Path: None  # path to pretrained audio codec  (w.o. LM)

  n_filters: 32
  causal: False
  dimension: 128
  quantizer_bins: 1024
  target_bandwidths: [1.5, 3., 6., 12., 18.] #TODO

  rvq_base_entropy_H1: [8.3902002, 7.52553906, 7.4798615] # from pretrained audio codec